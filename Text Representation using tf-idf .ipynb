{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecefc03",
   "metadata": {},
   "source": [
    "## Limitation of tf-idf\n",
    "* As n increased , dimensionality , sparsity increases \n",
    "* Doesn't capture relationship between words .\n",
    "* Doesn't address out of vocabulary problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eb3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus =[\n",
    "    \" Thor eating pizza, Loki is eating pizza , Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new eco-dot tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\",\n",
    "    \"something is amazing\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d675d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5f09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output=v.fit_transform(corpus) # while fit vector is generated and during transform it it is transformed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bea16a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 26, 'eating': 11, 'pizza': 23, 'loki': 18, 'is': 17, 'ironman': 16, 'ate': 8, 'already': 0, 'apple': 6, 'announcing': 5, 'new': 21, 'iphone': 15, 'tomorrow': 27, 'tesla': 25, 'model': 20, 'google': 13, 'pixel': 22, 'microsoft': 19, 'eco': 12, 'dot': 10, 'amazon': 3, 'am': 1, 'biryani': 9, 'and': 4, 'you': 28, 'are': 7, 'grapes': 14, 'something': 24, 'amazing': 2}\n"
     ]
    }
   ],
   "source": [
    "print(v.vocabulary_) # prinitng vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c595269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_char_ngrams', '_char_wb_ngrams', '_check_feature_names', '_check_n_features', '_check_params', '_check_stop_words_consistency', '_check_vocabulary', '_count_vocab', '_get_param_names', '_get_tags', '_limit_features', '_more_tags', '_parameter_constraints', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_sort_features', '_stop_words_id', '_tfidf', '_validate_data', '_validate_ngram_range', '_validate_params', '_validate_vocabulary', '_warn_for_unused_params', '_white_spaces', '_word_ngrams', 'analyzer', 'binary', 'build_analyzer', 'build_preprocessor', 'build_tokenizer', 'decode', 'decode_error', 'dtype', 'encoding', 'fit', 'fit_transform', 'fixed_vocabulary_', 'get_feature_names_out', 'get_params', 'get_stop_words', 'idf_', 'input', 'inverse_transform', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'norm', 'preprocessor', 'set_params', 'smooth_idf', 'stop_words', 'stop_words_', 'strip_accents', 'sublinear_tf', 'token_pattern', 'tokenizer', 'transform', 'use_idf', 'vocabulary', 'vocabulary_']\n"
     ]
    }
   ],
   "source": [
    "print(dir(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51d0b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['already', 'am', 'amazing', 'amazon', 'and', 'announcing', 'apple',\n",
       "       'are', 'ate', 'biryani', 'dot', 'eating', 'eco', 'google',\n",
       "       'grapes', 'iphone', 'ironman', 'is', 'loki', 'microsoft', 'model',\n",
       "       'new', 'pixel', 'pizza', 'something', 'tesla', 'thor', 'tomorrow',\n",
       "       'you'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature_names=v.get_feature_names_out()\n",
    "all_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbdd086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already 2.504077396776274\n",
      "am 2.504077396776274\n",
      "amazing 2.504077396776274\n",
      "amazon 2.504077396776274\n",
      "and 2.504077396776274\n",
      "announcing 1.4054651081081644\n",
      "apple 2.504077396776274\n",
      "are 2.504077396776274\n",
      "ate 2.504077396776274\n",
      "biryani 2.504077396776274\n",
      "dot 2.09861228866811\n",
      "eating 2.09861228866811\n",
      "eco 2.09861228866811\n",
      "google 2.504077396776274\n",
      "grapes 2.504077396776274\n",
      "iphone 2.504077396776274\n",
      "ironman 2.504077396776274\n",
      "is 1.1177830356563834\n",
      "loki 2.504077396776274\n",
      "microsoft 2.504077396776274\n",
      "model 2.504077396776274\n",
      "new 1.4054651081081644\n",
      "pixel 2.504077396776274\n",
      "pizza 2.504077396776274\n",
      "something 2.504077396776274\n",
      "tesla 2.504077396776274\n",
      "thor 2.504077396776274\n",
      "tomorrow 1.4054651081081644\n",
      "you 2.504077396776274\n"
     ]
    }
   ],
   "source": [
    "for word in all_feature_names:\n",
    "    indx=v.vocabulary_.get(word)\n",
    "    print(f\"{word} {v.idf_[indx]}\")\n",
    "#using v.idf_[indx] we are printing idf score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217d6b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Thor eating pizza, Loki is eating pizza , Ironman ate pizza already',\n",
       " 'Apple is announcing new iphone tomorrow']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1e258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24247317, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24247317, 0.        ,\n",
       "        0.        , 0.40642288, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24247317, 0.10823643, 0.24247317, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.7274195 , 0.        ,\n",
       "        0.        , 0.24247317, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.31652498, 0.5639436 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5639436 , 0.        , 0.25173606, 0.        , 0.        ,\n",
       "        0.        , 0.31652498, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31652498, 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_output.toarray()[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd482a",
   "metadata": {},
   "source": [
    "## Project using tf- idf is inside folder text classification based on e-commerce data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b4e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
